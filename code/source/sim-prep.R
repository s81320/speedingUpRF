#### checked this with Ulrike : ####
# Cleveland Daten um WK erweitern:
# 1) start with original Cleveland data set, 10 features / predictors, 1 target (CAD)
# 2) add column "prob" to the Cleveland table, probabilities generated by a logistic regression model (or any other model, like RF...) based on the original Cleveland data set. This is now the enriched Cleveland data set.

# later draw a bootstrap sample (or many...) from the enriched Cleveland data set
# and recreate / the CAD column : 
# CAD values are 0/1 drawn under a binomial distribution with parameter of success p=prob

library(dplyr)
library(ggplot2)

# 1) start with original Cleveland data set
# read cleveland data
load('data/data_SupMat4.rda')
df <- Cleve
df$CAD_fac <-  NULL

# 2) add column "prob" to the Cleveland table, 
# probabilities generated by a logistic regression model (or any other model, like RF...) 
# based on the original Cleveland data set. 
# This is now the enriched Cleveland data set.
model <- glm(CAD ~.,family=binomial(link='logit'), data=df)
df$prob <- model$fitted.values
df$prob <- glm(CAD ~.,family=binomial(link='logit'), data=df[,c(1:11)])$fitted.values


new_bootstrap <- function(df, resample){
  dfb<-df[resample,] # we need the prob to replace CAD 
  dfb$CAD <- factor(rbinom(303,1,dfb$prob))
  levels(dfb$CAD)<-list("No"="0","Yes"="1")
  return(dfb)
}

# this is really bad :
#df$prob <- ranger(CAD~. ,
#                  probability=T ,
# data=df[,c(1:11)])$predictions[,'Yes']
# especially when checking the grouped histogram: CAD No goes into 2nd and 3rd bin, but not into the 1st with prob 0-10%.

# check
# How often do the results from the fitted values agree with the original classification?
(as.numeric(ifelse(df$prob>0.5,1,2)) - as.numeric(df$CAD)) %>% abs() %>% mean()
idx.CAD.unchanged <- which(ifelse(df$prob>0.5,"Yes","No") == df$CAD) 
idx.CAD.unchanged %>% length/303 # uncommenting gets the same result as before

df[,'prob']  %>% 
  hist(xlab='dfb$prob'
       , main=paste('Histogram of probabilities for positive class in CAD\n(model',model$call[[1]],')'))
# for (60+60)/303 almost 40% of observations the probabilities are very clean (0-10% or 90-100%)
# less than (20+18)/303 about 13% are in the fuzzy range of 40 to 60% where an error in estimated prob of 10% (in the direction towards 50%!) would result in a different classification
# a large error in est. prob anywhere can mean an error in classification

ggplot(df,aes(x=prob,group=CAD,fill=CAD))+
  geom_histogram(position="dodge"
                # , binwidth=0.1
                 , bins = 10) +
  ggtitle(paste('Histogram of probabilities for positive class in CAD\n(model',model$call[[1]],')'))

# why don't I get the same counts for the 1st bin in the two plots (base hist and ggplot2 geom_histogram)??

# How are probabilities differently distributed for men and women?
df[df$Sex=='Female','prob'] %>% mean 
df[df$Sex=='Male','prob'] %>% mean 

df[df$Sex=='Female','prob'] %>% hist(main='histogram of probabilities for CAS Yes for Sex Female')
df[df$Sex=='Male','prob'] %>% hist(main='histogram of probabilities for CAS Yes for Sex Male')
# for men the outcome CAD == Yes occurs much more often in the data set than for women